{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéÆ CyborgMind MineRL Training on Google Colab\n",
                "\n",
                "This notebook trains a MineRL agent with PMM (Predictive Memory Module) on Google Colab with Cuberite server for visualization.\n",
                "\n",
                "## Features\n",
                "- **GPU Training**: Utilizes Colab's free GPU\n",
                "- **Cuberite Server**: Lightweight Minecraft server for visualization\n",
                "- **VNC Viewer**: Watch the agent play in real-time\n",
                "- **WandB Logging**: Track training metrics"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "!nvidia-smi\n",
                "\n",
                "# Install system dependencies\n",
                "!apt-get update -qq\n",
                "!apt-get install -qq -y openjdk-8-jdk xvfb x11vnc fluxbox websockify > /dev/null\n",
                "\n",
                "print(\"‚úÖ System dependencies installed\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone CyborgMind repository\n",
                "!git clone https://github.com/dawsonblock/cyborg_mind.git\n",
                "%cd cyborg_mind\n",
                "\n",
                "# Install Python dependencies\n",
                "!pip install -q torch torchvision numpy gymnasium wandb pyyaml tqdm matplotlib\n",
                "!pip install -q minerl\n",
                "\n",
                "print(\"‚úÖ Python dependencies installed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Setup Cuberite Server"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "# Download and setup Cuberite (lightweight C++ Minecraft server)\n",
                "cd /content\n",
                "if [ ! -d \"cuberite\" ]; then\n",
                "    echo \"Downloading Cuberite...\"\n",
                "    wget -q https://download.cuberite.org/linux-x86_64/Cuberite.tar.gz\n",
                "    tar -xzf Cuberite.tar.gz\n",
                "    mv Server cuberite\n",
                "    rm Cuberite.tar.gz\n",
                "    echo \"‚úÖ Cuberite downloaded\"\n",
                "else\n",
                "    echo \"‚úÖ Cuberite already exists\"\n",
                "fi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configure Cuberite for headless operation\n",
                "cuberite_settings = \"\"\"\n",
                "[Authentication]\n",
                "Authenticate=false\n",
                "AllowBungeeCord=false\n",
                "Server=sessionserver.mojang.com\n",
                "Address=/session/minecraft/hasJoined?username=%USERNAME%&serverId=%SERVERID%\n",
                "\n",
                "[Server]\n",
                "Description=CyborgMind Training Server\n",
                "MaxPlayers=4\n",
                "HardcoreEnabled=false\n",
                "AllowMultiLogin=true\n",
                "Port=25565\n",
                "\n",
                "[RCON]\n",
                "Enabled=true\n",
                "Port=25575\n",
                "Password=cyborg123\n",
                "\"\"\"\n",
                "\n",
                "with open('/content/cuberite/settings.ini', 'w') as f:\n",
                "    f.write(cuberite_settings)\n",
                "\n",
                "print(\"‚úÖ Cuberite configured\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import subprocess\n",
                "import time\n",
                "\n",
                "# Start Cuberite server in background\n",
                "cuberite_process = subprocess.Popen(\n",
                "    ['./Cuberite'],\n",
                "    cwd='/content/cuberite',\n",
                "    stdout=subprocess.PIPE,\n",
                "    stderr=subprocess.PIPE\n",
                ")\n",
                "\n",
                "print(\"‚è≥ Starting Cuberite server...\")\n",
                "time.sleep(10)  # Wait for server to start\n",
                "\n",
                "if cuberite_process.poll() is None:\n",
                "    print(\"‚úÖ Cuberite server running on port 25565\")\n",
                "    print(\"   Connect with Minecraft client to: <your-colab-ip>:25565\")\n",
                "else:\n",
                "    print(\"‚ùå Cuberite failed to start\")\n",
                "    print(cuberite_process.stderr.read().decode())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Setup VNC for Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "# Start virtual display\n",
                "export DISPLAY=:99\n",
                "Xvfb :99 -screen 0 1024x768x24 &\n",
                "sleep 2\n",
                "\n",
                "# Start window manager\n",
                "fluxbox &\n",
                "sleep 2\n",
                "\n",
                "# Start VNC server\n",
                "x11vnc -display :99 -forever -nopw -shared -rfbport 5900 &\n",
                "sleep 2\n",
                "\n",
                "# Start websockify for browser-based VNC\n",
                "websockify --web /usr/share/novnc 6080 localhost:5900 &\n",
                "\n",
                "echo \"‚úÖ VNC server started\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get Colab URL for VNC viewer\n",
                "from google.colab.output import eval_js\n",
                "\n",
                "print(\"üñ•Ô∏è VNC Viewer Setup\")\n",
                "print(\"=\"*50)\n",
                "print(\"Option 1: Use ngrok for external access\")\n",
                "print(\"Option 2: Use Colab's built-in port forwarding\")\n",
                "print(\"\\nTo view the agent, you'll need a VNC client or noVNC in browser.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Configure Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training configuration\n",
                "CONFIG = {\n",
                "    # Environment\n",
                "    'env_name': 'MineRLTreechop-v0',\n",
                "    'num_envs': 2,\n",
                "    'frame_stack': 4,\n",
                "    \n",
                "    # Model\n",
                "    'encoder': 'gru',  # 'gru', 'mamba', or 'mamba_gru'\n",
                "    'hidden_dim': 384,\n",
                "    'vision_dim': 256,\n",
                "    \n",
                "    # PMM (Memory)\n",
                "    'pmm_enabled': True,\n",
                "    'pmm_slots': 16,\n",
                "    'pmm_dim': 256,\n",
                "    \n",
                "    # Training\n",
                "    'total_steps': 100000,  # Reduce for testing\n",
                "    'horizon': 512,\n",
                "    'batch_size': 2048,\n",
                "    'learning_rate': 3e-4,\n",
                "    \n",
                "    # Logging\n",
                "    'use_wandb': False,  # Set to True and login for tracking\n",
                "    'log_freq': 1000,\n",
                "}\n",
                "\n",
                "print(\"üìã Training Configuration\")\n",
                "for k, v in CONFIG.items():\n",
                "    print(f\"   {k}: {v}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Optional: Login to WandB for experiment tracking\n",
                "# import wandb\n",
                "# wandb.login()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Train the Agent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.environ['DISPLAY'] = ':99'\n",
                "\n",
                "import torch\n",
                "import numpy as np\n",
                "\n",
                "# Build config dict for trainer\n",
                "config_dict = {\n",
                "    'env': {\n",
                "        'name': CONFIG['env_name'],\n",
                "        'size': [64, 64],\n",
                "        'max_steps': 18000,\n",
                "    },\n",
                "    'model': {\n",
                "        'encoder': CONFIG['encoder'],\n",
                "        'hidden_dim': CONFIG['hidden_dim'],\n",
                "        'vision_dim': CONFIG['vision_dim'],\n",
                "    },\n",
                "    'pmm': {\n",
                "        'enabled': CONFIG['pmm_enabled'],\n",
                "        'memory_dim': CONFIG['pmm_dim'],\n",
                "        'num_slots': CONFIG['pmm_slots'],\n",
                "        'write_rate_target_inv': 2000,\n",
                "        'gate_type': 'soft',\n",
                "        'temperature': 1.0,\n",
                "        'sharpness': 2.0,\n",
                "    },\n",
                "    'train': {\n",
                "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
                "        'num_envs': CONFIG['num_envs'],\n",
                "        'horizon': CONFIG['horizon'],\n",
                "        'batch_size': CONFIG['batch_size'],\n",
                "        'seq_len': 64,\n",
                "        'total_timesteps': CONFIG['total_steps'],\n",
                "        'learning_rate': CONFIG['learning_rate'],\n",
                "        'gamma': 0.99,\n",
                "        'gae_lambda': 0.95,\n",
                "        'clip_epsilon': 0.2,\n",
                "        'value_coef': 0.5,\n",
                "        'entropy_coef': 0.01,\n",
                "        'max_grad_norm': 0.5,\n",
                "        'ppo_epochs': 4,\n",
                "        'amp': torch.cuda.is_available(),\n",
                "        'compile': False,\n",
                "    }\n",
                "}\n",
                "\n",
                "print(f\"üîß Device: {config_dict['train']['device']}\")\n",
                "print(f\"üß† Encoder: {config_dict['model']['encoder']}\")\n",
                "print(f\"üíæ PMM: {'Enabled' if config_dict['pmm']['enabled'] else 'Disabled'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import and create trainer\n",
                "from cyborg_rl.trainers.ppo_trainer import PPOTrainer\n",
                "\n",
                "trainer = PPOTrainer(\n",
                "    config_dict=config_dict,\n",
                "    use_wandb=CONFIG['use_wandb']\n",
                ")\n",
                "\n",
                "print(\"‚úÖ Trainer initialized\")\n",
                "print(f\"   Observation dim: {trainer.obs_dim}\")\n",
                "print(f\"   Action dim: {trainer.action_dim}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Start training!\n",
                "print(\"üöÄ Starting Training...\")\n",
                "print(f\"   Total steps: {CONFIG['total_steps']:,}\")\n",
                "print(f\"   This may take a while on Colab free tier.\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "try:\n",
                "    trainer.train()\n",
                "    print(\"\\n‚úÖ Training Complete!\")\n",
                "except KeyboardInterrupt:\n",
                "    print(\"\\n‚èπÔ∏è Training interrupted by user\")\n",
                "except Exception as e:\n",
                "    print(f\"\\n‚ùå Training error: {e}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ Save & Download Checkpoint"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save final checkpoint\n",
                "import torch\n",
                "\n",
                "checkpoint = {\n",
                "    'config': config_dict,\n",
                "    'encoder_state_dict': trainer.encoder.state_dict(),\n",
                "    'policy_state_dict': trainer.policy.state_dict(),\n",
                "    'value_state_dict': trainer.value.state_dict(),\n",
                "    'obs_dim': trainer.obs_dim,\n",
                "    'action_dim': trainer.action_dim,\n",
                "}\n",
                "\n",
                "if trainer.use_pmm:\n",
                "    checkpoint['pmm_state_dict'] = trainer.pmm.state_dict()\n",
                "    checkpoint['pmm_proj_state_dict'] = trainer.pmm_proj.state_dict()\n",
                "\n",
                "save_path = '/content/cyborg_trained_agent.pt'\n",
                "torch.save(checkpoint, save_path)\n",
                "print(f\"‚úÖ Checkpoint saved to {save_path}\")\n",
                "\n",
                "# Download to local machine\n",
                "from google.colab import files\n",
                "files.download(save_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7Ô∏è‚É£ Evaluate Agent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run evaluation\n",
                "from evaluate_minerl_agent import AgentEvaluator\n",
                "\n",
                "evaluator = AgentEvaluator(\n",
                "    checkpoint_path=save_path,\n",
                "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
                "    deterministic=True\n",
                ")\n",
                "\n",
                "results = evaluator.evaluate(\n",
                "    env_name=CONFIG['env_name'],\n",
                "    num_episodes=5,  # Reduced for speed\n",
                ")\n",
                "\n",
                "print(\"\\nüìä Evaluation Results\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Mean Reward: {results['summary']['mean_reward']:.2f}\")\n",
                "print(f\"Mean Length: {results['summary']['mean_length']:.0f}\")\n",
                "print(f\"Success Rate: {results['summary']['success_rate']:.1%}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üßπ Cleanup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Stop Cuberite server\n",
                "if 'cuberite_process' in dir() and cuberite_process.poll() is None:\n",
                "    cuberite_process.terminate()\n",
                "    print(\"‚úÖ Cuberite server stopped\")\n",
                "\n",
                "# Kill VNC processes\n",
                "!pkill -f x11vnc\n",
                "!pkill -f Xvfb\n",
                "!pkill -f websockify\n",
                "print(\"‚úÖ VNC processes stopped\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìù Notes\n",
                "\n",
                "### Connecting to Cuberite\n",
                "To view the Minecraft world:\n",
                "1. Use port forwarding: `!ngrok tcp 25565`\n",
                "2. Connect with Minecraft Java Edition to the ngrok URL\n",
                "\n",
                "### Performance Tips\n",
                "- Use Colab Pro for better GPUs and longer sessions\n",
                "- Reduce `num_envs` if running out of memory\n",
                "- Enable AMP (`amp: True`) for faster training on GPU\n",
                "\n",
                "### Troubleshooting\n",
                "- If MineRL fails to install, try: `!pip install minerl --no-deps`\n",
                "- If GPU runs out of memory, reduce `batch_size` or `hidden_dim`"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        },
        "accelerator": "GPU"
    },
    "nbformat": 4,
    "nbformat_minor": 4
}