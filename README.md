# ğŸ§  CyborgMind V2.6

> **Production-Grade Game AI & RL Brain System**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Training](https://img.shields.io/badge/Training-MineRL%20%7C%20Gym-orange)]()
[![Deploy](https://img.shields.io/badge/Deploy-Docker%20%7C%20FastAPI-green)]()
[![Version](https://img.shields.io/badge/version-2.6.0-brightgreen)]()

**Production-hardened RL brain for game AI, NPC control, and autonomous agents.** Features universal environment adapters, dynamic memory, recurrent processing, and enterprise deployment infrastructure.

### ğŸ†• V2.6 Highlights
- âœ… **CC3D Removed** - Pure game/RL focus
- âœ… **Hardened Adapters** - Production validation for Gym/MineRL
- âœ… **Docker Deployment** - Multi-stage builds with GPU
- âœ… **Monitoring** - Prometheus + Grafana dashboards
- âœ… **Type Safe** - Full validation with clean errors

**[ğŸ“– V2.6 Release Notes](https://github.com/dawsonblock/cyborg_mind/blob/main/docs/V2.6_RELEASE_NOTES.md)** | **[ğŸ”„ Migration Guide](https://github.com/dawsonblock/cyborg_mind/blob/main/docs/V2.6_MIGRATION_GUIDE.md)** | **[ğŸ—ï¸ V2.6 Architecture](https://github.com/dawsonblock/cyborg_mind/blob/main/docs/V2.6_ARCHITECTURE.md)**

---

## âœ¨ Highlights

- ğŸ¯ **Universal Adapters**: Works with MineRL, Gym, custom envs - one brain, any task
- ğŸ§  **Emotion-Consciousness**: 8-channel emotions + 32D thoughts + 64D workspace
- ğŸ’¾ **Dynamic Memory**: Auto-expanding PMM (256â†’2048 slots) with garbage collection
- ğŸ”„ **Recurrent Processing**: LSTM + FRNN for temporal coherence
- ğŸš€ **Production Ready**: FastAPI server + web visualizer + Docker
- ğŸ“Š **Full Observability**: TensorBoard + real-time emotion visualization

---

## ğŸ¬ Quick Start

### Option 1: Docker (Recommended for V2.6)

```bash
# Clone and build
git clone https://github.com/dawsonblock/cyborg_mind.git
cd cyborg_mind
docker-compose up --build

# Access services
open http://localhost:8000/docs    # API documentation
open http://localhost:3000         # Grafana dashboards (admin/admin)
```

### Option 2: Local Installation

```bash
# Clone repository
git clone https://github.com/dawsonblock/cyborg_mind.git
cd cyborg_mind

# Install dependencies
pip install -e .

# Verify V2.6 installation
python -c "from cyborg_mind_v2.envs import GymAdapter; print('âœ“ CyborgMind V2.6 ready!')"
```

### Run Demo

```bash
# 1. Start API server
uvicorn cyborg_mind_v2.deployment.api_server:app --host 0.0.0.0 --port 8000

# 2. Open web visualizer
cd frontend/demo && python -m http.server 8080

# 3. Visit http://localhost:8080 and click "Connect"
```

### Train on MineRL

```bash
# Complete pipeline: BC â†’ Distillation â†’ PPO
bash experiments/run_full_pipeline.sh

# Or run individually:
bash experiments/run_treechop_teacher_bc.sh  # Teacher BC
bash experiments/run_treechop_ppo.sh          # PPO training
```

### Train on Gym

```bash
# CartPole demo
python -c "
from cyborg_mind_v2.envs import create_adapter
from cyborg_mind_v2.integration import CyborgMindController

adapter = create_adapter('gym', 'CartPole-v1')
controller = CyborgMindController()

for ep in range(10):
    obs = adapter.reset()
    done = False
    reward_sum = 0
    while not done:
        action = controller.step(['agent_0'], obs.pixels.unsqueeze(0),
                                obs.scalars.unsqueeze(0), obs.goal.unsqueeze(0))[0]
        obs, reward, done, _ = adapter.step(action)
        reward_sum += reward
    print(f'Episode {ep+1}: Reward = {reward_sum}')
"
```

---

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CyborgMind V2 System                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   MineRL     â”‚    â”‚  Gymnasium   â”‚    â”‚  Synthetic   â”‚  â”‚
â”‚  â”‚   Adapter    â”‚    â”‚   Adapter    â”‚    â”‚   Dataset    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                            â”‚                                â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚         â”‚  (pixels, scalars, goal) â†’ action_idx  â”‚          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                            â”‚                                â”‚
â”‚  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â–¼â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—  â”‚
â”‚  â•‘              BrainCyborgMind (2.3M params)           â•‘  â”‚
â”‚  â•‘                                                       â•‘  â”‚
â”‚  â•‘  Vision â†’ PMM â†’ LSTM â†’ [Action, Value, Emotion,     â•‘  â”‚
â”‚  â•‘                         Thought, Workspace]          â•‘  â”‚
â”‚  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Brain Components

| Component | Description | Dimensions |
|-----------|-------------|------------|
| **Vision Adapter** | CNN encoder for RGB images | 512 |
| **Dynamic PMM** | Content-addressable memory | 256-2048 slots Ã— 128 dims |
| **LSTM Core** | Temporal processing | 512 hidden |
| **FRNN Workspace** | Global consciousness (GWT) | 64 |
| **Emotion System** | Affect model (valence, arousal, etc.) | 8 channels |
| **Thought Vector** | Persistent cognition | 32 |

**Total Parameters**: 2.3M (brain) + 87M (optional teacher)

---

## ğŸ“ Training Pipelines

### 1. Behavior Cloning (BC)

Train from expert demonstrations:

```bash
bash experiments/run_treechop_teacher_bc.sh
```

**Results**: ~75% action prediction accuracy on MineRL dataset

### 2. Proximal Policy Optimization (PPO)

Reinforcement learning from scratch or fine-tuning:

```bash
bash experiments/run_treechop_ppo.sh
```

**Results**: See [docs/MINERL_RESULTS.md](docs/MINERL_RESULTS.md)

### 3. Full Pipeline (Recommended)

Teacher BC â†’ Student Distillation â†’ PPO Fine-tuning:

```bash
bash experiments/run_full_pipeline.sh
```

This combines the best of imitation and reinforcement learning!

---

## ğŸŒ Universal Environment Adapters

CyborgMind works with **any** environment via adapters:

```python
from cyborg_mind_v2.envs import create_adapter

# MineRL
adapter = create_adapter("minerl", "MineRLTreechop-v0")

# Gym
adapter = create_adapter("gym", "CartPole-v1")

# Custom (implement BrainEnvAdapter protocol)
class MyAdapter:
    def reset(self) -> BrainInputs: ...
    def step(self, action_idx: int) -> Tuple[BrainInputs, float, bool, Dict]: ...
```

All adapters provide the same interface:
- **Input**: `(pixels, scalars, goal)` â†’ unified brain format
- **Output**: `action_idx` â†’ environment-specific action

See [docs/ADAPTER_SYSTEM.md](docs/ADAPTER_SYSTEM.md) for details.

---

## ğŸš€ Deployment

### Docker

```bash
# Build
docker build -t cyborgmind:latest .

# Run
docker run -d --gpus all -p 8000:8000 cyborgmind:latest
```

### FastAPI Server

```bash
# Start server
uvicorn cyborg_mind_v2.deployment.api_server:app --host 0.0.0.0 --port 8000

# Test
curl -X POST http://localhost:8000/reset -H "Content-Type: application/json" \
  -d '{"agent_id": "test_agent"}'
```

**Endpoints**:
- `POST /reset` - Initialize agent
- `POST /step` - Get action from observation
- `GET /state/{agent_id}` - Query brain state
- `GET /metrics` - Performance metrics

### Web Visualizer

Open `frontend/demo/index.html` in browser:
- Real-time emotion visualization (8 channels)
- Thought vector heatmap (32D)
- Memory pressure tracking
- Action/value display

---

## ğŸ“Š Benchmarks

### MineRL TreeChop-v0

| Method | Mean Reward | Training Time | Checkpoint |
|--------|-------------|---------------|------------|
| **BC (Teacher)** | TBD | 1-2 hours | `real_teacher_treechop.pt` |
| **PPO (from scratch)** | TBD | 2-4 hours | `treechop_brain.pt` |
| **Pipeline (BCâ†’PPO)** | TBD | 3-6 hours | `treechop_brain.pt` |

### Gym CartPole-v1

| Method | Mean Reward | Solved? |
|--------|-------------|---------|
| **PPO** | 195+ | âœ… |

See detailed results in [docs/MINERL_RESULTS.md](docs/MINERL_RESULTS.md)

---

## ğŸ“‚ Project Structure

```
cyborg_mind/
â”œâ”€â”€ cyborg_mind_v2/
â”‚   â”œâ”€â”€ capsule_brain/       # Brain architecture
â”‚   â”‚   â””â”€â”€ policy/
â”‚   â”‚       â””â”€â”€ brain_cyborg_mind.py
â”‚   â”œâ”€â”€ envs/                # Environment adapters
â”‚   â”‚   â”œâ”€â”€ base_adapter.py
â”‚   â”‚   â”œâ”€â”€ minerl_adapter.py
â”‚   â”‚   â””â”€â”€ gym_adapter.py
â”‚   â”œâ”€â”€ integration/         # Controller
â”‚   â”‚   â””â”€â”€ cyborg_mind_controller.py
â”‚   â”œâ”€â”€ training/            # Training scripts
â”‚   â”‚   â”œâ”€â”€ train_cyborg_mind_ppo.py
â”‚   â”‚   â”œâ”€â”€ train_real_teacher_bc.py
â”‚   â”‚   â””â”€â”€ dist/            # Distributed training
â”‚   â”œâ”€â”€ deployment/          # API & monitoring
â”‚   â”‚   â””â”€â”€ api_server.py
â”‚   â””â”€â”€ data/                # Datasets
â”œâ”€â”€ configs/                 # YAML configurations
â”‚   â”œâ”€â”€ treechop_ppo.yaml
â”‚   â”œâ”€â”€ treechop_bc.yaml
â”‚   â””â”€â”€ gym_cartpole.yaml
â”œâ”€â”€ experiments/             # Training scripts
â”‚   â”œâ”€â”€ run_treechop_ppo.sh
â”‚   â”œâ”€â”€ run_treechop_teacher_bc.sh
â”‚   â””â”€â”€ run_full_pipeline.sh
â”œâ”€â”€ frontend/demo/           # Web visualizer
â”œâ”€â”€ notebooks/               # Colab demos
â”‚   â””â”€â”€ cyborg_mind_quickstart.ipynb
â”œâ”€â”€ docs/                    # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE_V3.md
â”‚   â”œâ”€â”€ DEPLOYMENT.md
â”‚   â””â”€â”€ MINERL_RESULTS.md
â””â”€â”€ checkpoints/             # Saved models
```

---

## ğŸ”§ Configuration

Use YAML configs for reproducible experiments:

```yaml
# configs/treechop_ppo.yaml
env:
  adapter: "minerl"
  name: "MineRLTreechop-v0"

ppo:
  learning_rate: 3e-4
  gamma: 0.99
  clip_epsilon: 0.2

training:
  device: "cuda"
  num_episodes: 1000
```

Load and use:

```python
import yaml

with open("configs/treechop_ppo.yaml") as f:
    config = yaml.safe_load(f)
```

---

## ğŸ§ª Notebooks

Interactive demos in `notebooks/`:

**Quickstart**: [`cyborg_mind_quickstart.ipynb`](notebooks/cyborg_mind_quickstart.ipynb)
- Train on synthetic data
- Run Gym CartPole demo
- Visualize brain state (emotions, thoughts, workspace)

**Colab**: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dawsonblock/cyborg_mind/blob/main/notebooks/cyborg_mind_quickstart.ipynb)

---

## ğŸ“– Documentation

| Document | Description |
|----------|-------------|
| [V2.6_ARCHITECTURE.md](docs/V2.6_ARCHITECTURE.md) | **V2.6 system architecture** |
| [V2.6_RELEASE_NOTES.md](docs/V2.6_RELEASE_NOTES.md) | **V2.6 release notes** |
| [V2.6_MIGRATION_GUIDE.md](docs/V2.6_MIGRATION_GUIDE.md) | **V2.5 â†’ V2.6 migration** |
| [ARCHITECTURE_V3.md](docs/ARCHITECTURE_V3.md) | Legacy architecture docs |
| [DEPLOYMENT.md](docs/DEPLOYMENT.md) | Production deployment guide |
| [MINERL_RESULTS.md](docs/MINERL_RESULTS.md) | Training results & benchmarks |
| [ADAPTER_SYSTEM.md](docs/ADAPTER_SYSTEM.md) | Environment adapter guide |

---

## ğŸ”¬ Research Foundations

CyborgMind V2 builds on:

- **Global Workspace Theory** (Baars, 1988): FRNN workspace for consciousness
- **Emotion as Computation** (Minsky, 2006): 8-channel affect model
- **PMM Memory** (Graves et al.): Content-addressable episodic storage
- **PPO** (Schulman et al., 2017): Robust policy optimization
- **Behavior Cloning** (Pomerleau, 1989): Learning from demonstrations

---

## ğŸ¤ Contributing

Contributions welcome! Areas of interest:

- New environment adapters (Unity, Unreal, robotics)
- Improved memory systems (Transformer-XL, MERLIN)
- Multi-agent communication
- Language grounding
- Benchmarks on more tasks

---

## ğŸ¯ Roadmap

### V2.6 (Current - Production Hardening)
- âœ… CC3D removal (game/RL focus)
- âœ… Hardened adapters with validation
- âœ… Docker deployment infrastructure
- âœ… Prometheus + Grafana monitoring
- âœ… Full type safety and error handling

### V2.7 (Next)
- [ ] Multi-agent coordination
- [ ] Hierarchical RL with options
- [ ] Transformer-based world models
- [ ] Real-time environment streaming
- [ ] Advanced curriculum learning

### V3.0 (Future)
- [ ] Language instruction following
- [ ] Open-ended exploration
- [ ] Meta-learning
- [ ] Unity/Unreal integration

---

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE)

---

## ğŸ™ Acknowledgments

- **MineRL Team** for the benchmark environment
- **OpenAI** for Gym and PPO
- **Anthropic** for Claude AI development assistance
- **PyTorch Team** for the ML framework

---

## ğŸ“¬ Contact

- **GitHub Issues**: [Report bugs or request features](https://github.com/dawsonblock/cyborg_mind/issues)
- **Author**: Dawson Block
- **Email**: [Your Email]

---

## ğŸ“Š Citation

If you use CyborgMind V2 in your research:

```bibtex
@software{cyborgmind_v26,
  title={CyborgMind V2.6: Production-Grade Game AI & RL Brain System},
  author={Block, Dawson},
  year={2025},
  version={2.6.0},
  url={https://github.com/dawsonblock/cyborg_mind}
}
```

---

<div align="center">

**Built with ğŸ§  and â¤ï¸**

[Documentation](docs/) â€¢ [Quickstart](notebooks/cyborg_mind_quickstart.ipynb) â€¢ [Results](docs/MINERL_RESULTS.md)

</div>
